"""
å…¨æ™¯å›¾åƒå¤„ç†å™¨æ ¸å¿ƒç±»
åè°ƒæ‰€æœ‰APIæœåŠ¡å®Œæˆå®Œæ•´çš„å¤„ç†æµç¨‹
"""

import os
import sys
import logging
import time
import json
import shutil
from typing import List, Dict
from PIL import Image

# æ·»åŠ é¡¹ç›®è·¯å¾„ï¼ˆå¿…é¡»åœ¨ from utils/config ä¹‹å‰ï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))
project_dir = os.path.join(current_dir, '..')
sys.path.insert(0, project_dir)

from utils.api_utils import APIClient


logger = logging.getLogger(__name__)

class PanoramaProcessor:
    """å…¨æ™¯å›¾åƒå¤„ç†å™¨ - åè°ƒæ‰€æœ‰APIæœåŠ¡"""
    
    def __init__(self, output_root_dir: str = "output", api_version: str = "original", output_file: str = "results.json", num_interpolations: int = 9):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            output_root_dir: è¾“å‡ºæ ¹ç›®å½•
            api_version: APIç‰ˆæœ¬é€‰æ‹©ï¼Œ'original' æˆ– 'shared_left'
            output_file: è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤ results.jsonï¼‰
            num_interpolations: æ’å€¼å›¾åƒæ•°é‡ï¼ˆé»˜è®¤9ï¼‰ï¼Œæ§åˆ¶åœ¨ä¸¤å¼ å›¾ä¹‹é—´ç”Ÿæˆå¤šå°‘ä¸ªæ’å€¼å¸§
        """
        self.output_root_dir = output_root_dir
        self.api_version = api_version
        self.output_file = output_file
        self.num_interpolations = num_interpolations
        
        # ä½¿ç”¨ç»Ÿä¸€é…ç½®
        from config.api_config import get_api_ports, get_gpu_id, API_BASE_URL
        
        self.API_PORTS = get_api_ports(api_version)
        self.API_BASE_URL = API_BASE_URL
        gpu_id = get_gpu_id(api_version)
        
        logger.info(f"ğŸ”„ ä½¿ç”¨ {api_version} ç‰ˆæœ¬API (ç«¯å£ {self.API_PORTS['preprocess']}-{self.API_PORTS['quality']}, GPU {gpu_id})")
        
        self.api_client = APIClient(API_BASE_URL)
        
        os.makedirs(self.output_root_dir, exist_ok=True)
        logger.info(f"åˆ›å»ºè¾“å‡ºæ ¹ç›®å½•: {self.output_root_dir}")
    
    # ==================== å·¥å…·æ–¹æ³• ====================
    
    def _extract_group_dir(self, file_path: str) -> str:
        """ä»æ–‡ä»¶è·¯å¾„ä¸­æå– group_xxxx ç›®å½•çš„ç»å¯¹è·¯å¾„"""
        import re
        normalized = file_path.replace('\\', '/')
        match = re.search(r'/group_\d+/', normalized)
        if match:
            pos = normalized.find(match.group(0))
            group_root_dir = file_path[:pos + len(match.group(0)) - 1]
            return os.path.abspath(group_root_dir)
        raise ValueError(f"æ— æ³•ä»è·¯å¾„æå–ç»„ç›®å½•: {file_path}")
    
    def _call_api(self, port: int, endpoint: str, data: dict, description: str = "APIè°ƒç”¨") -> dict:
        """è°ƒç”¨APIå¹¶è¿”å›å“åº”ï¼Œå¤±è´¥æ—¶ç›´æ¥æŠ›å‡ºå¼‚å¸¸"""
        response = self.api_client.call_api(port=port, endpoint=endpoint, data=data)
        if not response.get('success'):
            raise RuntimeError(f"{description}å¤±è´¥: {response.get('error')}")
        return response
    
    def _batch_super_resolve(self, input_paths: List[str]) -> list:
        """é€šç”¨æ‰¹é‡è¶…åˆ†è¾¨ç‡ - è°ƒç”¨ OSEDiff æ‰¹é‡API
        
        Args:
            input_paths: å¾…è¶…åˆ†çš„å›¾åƒè·¯å¾„åˆ—è¡¨
        Returns:
            APIè¿”å›çš„é€å›¾ç»“æœåˆ—è¡¨ï¼Œæ¯é¡¹å« success, output_path ç­‰å­—æ®µ
        """
        group_root_dir = self._extract_group_dir(input_paths[0])
        response = self._call_api(
            self.API_PORTS['osediff'], 'super_resolution_batch',
            {'input_paths': input_paths, 'output_dir': group_root_dir, 'align_method': 'adain'},
            "æ‰¹é‡è¶…åˆ†"
        )
        return response.get('results', [])
    
    # ==================== æµç¨‹å­æ–¹æ³•ï¼ˆæŒ‰è°ƒç”¨é¡ºåºï¼‰====================
    
    # æ­¥éª¤3: è´¨é‡è¯„ä¼°
    def evaluate_quality(self, pairs_data: List[Dict]) -> List[Dict]:
        """è¯„ä¼°å›¾åƒå¯¹è´¨é‡
        
        åªä¼ é€’å¿…è¦å­—æ®µï¼špair_image, interval, main_params, rand_params, yaw_interval
        """
        logger.info(f"å¼€å§‹è´¨é‡è¯„ä¼° {len(pairs_data)} ä¸ªå›¾åƒå¯¹")
        
        # åªæå–å¿…è¦å­—æ®µï¼Œé¿å…ä¼ è¾“å†—ä½™æ•°æ®
        quality_pairs_data = []
        for pair_data in pairs_data:
            quality_pairs_data.append({
                'pair_image': pair_data.get('super_resolved') or pair_data.get('pair_image'),
                'interval': pair_data.get('interval'),
                'main_params': pair_data.get('main_params'),
                'rand_params': pair_data.get('rand_params'),
                'yaw_interval': pair_data.get('yaw_interval')
            })
        
        response = self._call_api(
            self.API_PORTS['quality'], 'evaluate_pairs',
            {'pairs_data': quality_pairs_data},
            "è´¨é‡è¯„ä¼°"
        )
        results = response.get('results', [])
        logger.info(f"è´¨é‡è¯„ä¼°å®Œæˆï¼Œè¯„ä¼°äº† {len(results)} ä¸ªå›¾åƒå¯¹")
        return results
    
    # æ­¥éª¤4: è´¨é‡è¿‡æ»¤
    def filter_high_quality_results_by_group(self, quality_results: List[Dict], threshold: float = 0.7) -> List[Dict]:
        """æŒ‰ç»„è¿‡æ»¤é«˜è´¨é‡ç»“æœï¼ˆåœ¨åŒä¸€yawåŒºé—´å†…å–æœ€ä½åˆ†ï¼‰"""
        # å…ˆæŒ‰intervalåˆ†ç»„
        interval_dict = {}
        for result in quality_results:
            interval = result.get('interval', 0)
            if interval not in interval_dict:
                interval_dict[interval] = []
            interval_dict[interval].append(result)
        
        # å¯¹æ¯ä¸ªintervalå†…çš„pairå–æœ€ä½åˆ†
        filtered_results = []
        for interval, results in interval_dict.items():
            scores = [float(r['final_score']) for r in results 
                      if r.get('final_score') is not None]
            
            if scores:
                min_score = min(scores)
                
                if min_score >= threshold:
                    logger.info(f"yawåŒºé—´ {interval} é€šè¿‡è´¨é‡ç­›é€‰ (æœ€ä½åˆ†: {min_score:.3f})")
                    filtered_results.extend(results)
                else:
                    logger.info(f"yawåŒºé—´ {interval} æœªé€šè¿‡è´¨é‡ç­›é€‰ (æœ€ä½åˆ†: {min_score:.3f})")
            else:
                logger.warning(f"yawåŒºé—´ {interval} æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æ•°ï¼Œè·³è¿‡")
        
        logger.info(f"è´¨é‡è¿‡æ»¤å®Œæˆï¼Œä» {len(quality_results)} ä¸ªç»“æœä¸­ä¿ç•™äº† {len(filtered_results)} ä¸ª")
        return filtered_results
    
    # æ­¥éª¤4.5: æè¿°ç”Ÿæˆ
    def generate_panorama2_descriptions(self, filtered_results: List[Dict], panorama2_path: str, group_id: int) -> Dict:
        """ä¸º panorama2 çš„å³å›¾ç”Ÿæˆæ–‡æœ¬æè¿°ï¼ˆéå…³é”®æ­¥éª¤ï¼Œå¤±è´¥ä¸ä¸­æ–­æµç¨‹ï¼‰"""
        logger.info(f"å¼€å§‹ä¸º panorama2 çš„å³å›¾ç”Ÿæˆæè¿°")
        
        panorama2_basename = os.path.splitext(os.path.basename(panorama2_path))[0]
        panorama2_right_images = []
        group_root_dir = None
        
        try:
            for result in filtered_results:
                pair_image_path = result.get('image_path') or result.get('pair_image')
                if not pair_image_path or panorama2_basename not in os.path.basename(pair_image_path):
                    continue
                
                # æå–å³å›¾
                pair_img = Image.open(pair_image_path)
                width, height = pair_img.size
                right_img = pair_img.crop((width // 2, 0, width, height))
                
                if not group_root_dir:
                    group_root_dir = self._extract_group_dir(pair_image_path)
                
                desc_dir = os.path.join(group_root_dir, 'descriptions')
                os.makedirs(desc_dir, exist_ok=True)
                
                base_name = os.path.splitext(os.path.basename(pair_image_path))[0]
                right_img_path = os.path.join(desc_dir, f"{base_name}_right.jpg")
                right_img.save(right_img_path, quality=95)
                
                panorama2_right_images.append({
                    'image_path': right_img_path,
                    'original_pair': pair_image_path,
                    'interval': result.get('interval'),
                    'yaw_interval': result.get('yaw_interval')
                })
            
            if not panorama2_right_images:
                return {'success': True, 'descriptions': []}
            
            # æ‰¹é‡ç”Ÿæˆæè¿°
            image_paths = [img['image_path'] for img in panorama2_right_images]
            response = self._call_api(
                self.API_PORTS['quality'], 'generate_descriptions',
                {'image_paths': image_paths},
                "æè¿°ç”Ÿæˆ"
            )
            
            descriptions = response.get('results', [])
            for img_info, desc_result in zip(panorama2_right_images, descriptions):
                img_info['description'] = desc_result.get('description', '')
            
            # ä¿å­˜æè¿°åˆ° JSON
            if group_root_dir:
                desc_json_path = os.path.join(group_root_dir, 'descriptions', 'panorama2_right_descriptions.json')
                with open(desc_json_path, 'w', encoding='utf-8') as f:
                    json.dump(panorama2_right_images, f, indent=2, ensure_ascii=False)
            
            logger.info(f"æè¿°ç”Ÿæˆå®Œæˆï¼Œå…± {len(descriptions)} æ¡")
            return {'success': True, 'descriptions': panorama2_right_images}
            
        except Exception as e:
            logger.warning(f"æè¿°ç”Ÿæˆå¤±è´¥ï¼ˆéå…³é”®ï¼‰: {e}")
            return {'success': False, 'error': str(e)}
    
    # æ­¥éª¤5: åˆ‡åˆ† + æ’å€¼ç”Ÿæˆ + æ’å€¼è¶…åˆ†
    def interpolate_and_super_resolve(self, filtered_results: List[Dict], group_id: int,
                                      panorama_path1: str, panorama_path2: str) -> tuple:
        """åˆ‡åˆ†å›¾åƒå¯¹ã€ç”Ÿæˆæ’å€¼å›¾åƒå¹¶è¿›è¡Œè¶…åˆ†å¤„ç†
        
        Returns:
            (split_results, interpolated_results): åˆ‡åˆ†ç»“æœå’Œè¶…åˆ†åçš„æ’å€¼ç»“æœ
        """
        # 1. åˆ‡åˆ†å›¾åƒå¯¹ä¸ºå·¦å³ä¸¤éƒ¨åˆ†
        split_results = []
        for result in filtered_results:
            pair_image_path = result.get('pair_image', '')
            if not pair_image_path or not os.path.exists(pair_image_path):
                continue
            
            group_root_dir = self._extract_group_dir(pair_image_path)
            interpolated_dir = os.path.join(group_root_dir, "interpolated")
            os.makedirs(interpolated_dir, exist_ok=True)
            
            img = Image.open(pair_image_path)
            mid = img.width // 2
            left_img = img.crop((0, 0, mid, img.height))
            right_img = img.crop((mid, 0, img.width, img.height))
            
            base_name = os.path.splitext(os.path.basename(pair_image_path))[0]
            left_path = os.path.join(interpolated_dir, f"{base_name}_left.jpg")
            right_path = os.path.join(interpolated_dir, f"{base_name}_right.jpg")
            left_img.save(left_path)
            right_img.save(right_path)
            
            split_results.append({
                'pair_image': pair_image_path, 'left_image': left_path, 'right_image': right_path,
                'main_params': result.get('main_params'), 'rand_params': result.get('rand_params'),
                'interval': result.get('interval'), 'yaw_interval': result.get('yaw_interval'),
                'group_id': group_id
            })
        
        logger.info(f"åˆ‡åˆ†å®Œæˆï¼Œç”Ÿæˆäº† {len(split_results)} ä¸ªç»“æœ")
        
        # 2. ç”Ÿæˆæ’å€¼å›¾åƒ
        interp_resp = self._call_api(
            self.API_PORTS['preprocess'], 'generate_interpolated_images',
            {'split_results': split_results, 'panorama1_path': panorama_path1,
             'panorama2_path': panorama_path2, 'group_id': group_id,
             'num_interpolations': self.num_interpolations},
            "æ’å€¼å›¾åƒç”Ÿæˆ"
        )
        interpolated_results = interp_resp.get('results', [])
        
        # 3. æ”¶é›†æ’å€¼å›¾åƒè·¯å¾„å¹¶æ‰¹é‡è¶…åˆ†
        input_paths = []
        interp_img_refs = []
        for interp_group in interpolated_results:
            for interp_img in interp_group.get('interpolated_images', []):
                input_path = interp_img.get('path')
                if input_path and os.path.exists(input_path):
                    input_paths.append(input_path)
                    interp_img_refs.append(interp_img)
        
        if input_paths:
            sr_results = self._batch_super_resolve(input_paths)
            
            # ç§»åŠ¨åˆ° interpolated_sr ç›®å½•å¹¶å›å¡«è·¯å¾„
            group_root_dir = self._extract_group_dir(input_paths[0])
            sr_output_dir = os.path.join(group_root_dir, "interpolated_sr")
            os.makedirs(sr_output_dir, exist_ok=True)
            
            sr_count = 0
            for interp_img, sr_result in zip(interp_img_refs, sr_results):
                if sr_result.get('success'):
                    output_path = sr_result['output_path']
                    target_path = os.path.join(sr_output_dir, os.path.basename(output_path))
                    shutil.move(output_path, target_path)
                    interp_img['super_resolved'] = target_path
                    sr_count += 1
            logger.info(f"æ’å€¼å›¾åƒè¶…åˆ†å¤„ç†å®Œæˆï¼ŒæˆåŠŸ {sr_count}/{len(input_paths)}")
        
        return split_results, interpolated_results
    
    # æ­¥éª¤6: åˆ›å»ºæœ€ç»ˆæ•°æ®
    def create_final_data_with_interpolation(self, split_results: List[Dict], interpolated_results: List[Dict], 
                                            group_id: int, panorama1_path: str, panorama2_path: str, 
                                            desc_result: Dict = None) -> List[Dict]:
        """åˆ›å»ºåŒ…å«æ’å€¼å›¾åƒçš„æœ€ç»ˆæ•°æ®"""
        logger.info(f"åˆ›å»ºåŒ…å«æ’å€¼çš„æœ€ç»ˆæ•°æ®")
        
        # æ„å»ºæè¿°å­—å…¸ï¼Œæ–¹ä¾¿æŒ‰ interval æŸ¥æ‰¾
        descriptions_by_interval = {}
        if desc_result and desc_result.get('success') and desc_result.get('descriptions'):
            for desc in desc_result.get('descriptions', []):
                interval = desc.get('interval')
                if interval:
                    descriptions_by_interval[interval] = desc.get('description', '')
        
        final_data = []
        
        # æŒ‰intervalç»„ç»‡æ•°æ®
        interval_to_panoramas = {}  # {interval: {'panorama1': {...}, 'panorama2': {...}}}
        
        for split_result in split_results:
            interval = split_result.get('interval')
            if interval not in interval_to_panoramas:
                interval_to_panoramas[interval] = {}
            
            # åˆ¤æ–­æ˜¯panorama1è¿˜æ˜¯panorama2
            pair_image = split_result.get('pair_image', '')
            pair_basename = os.path.splitext(os.path.basename(pair_image))[0]
            panorama1_basename = os.path.splitext(os.path.basename(panorama1_path))[0]
            panorama2_basename = os.path.splitext(os.path.basename(panorama2_path))[0]
            
            if pair_basename.startswith(panorama1_basename):
                interval_to_panoramas[interval]['panorama1'] = split_result
            elif pair_basename.startswith(panorama2_basename):
                interval_to_panoramas[interval]['panorama2'] = split_result
            else:
                # å¦‚æœæ— æ³•åˆ¤æ–­ï¼Œå°è¯•ä»pair_imageè·¯å¾„åˆ¤æ–­
                if panorama1_basename in pair_image:
                    interval_to_panoramas[interval]['panorama1'] = split_result
                else:
                    interval_to_panoramas[interval]['panorama2'] = split_result
        
        # ä¸ºæ¯ä¸ªintervalåˆ›å»ºæœ€ç»ˆæ•°æ®æ¡ç›®
        for interval, panoramas in sorted(interval_to_panoramas.items()):
            if 'panorama1' not in panoramas or 'panorama2' not in panoramas:
                logger.warning(f"Interval {interval} ç¼ºå°‘å®Œæ•´çš„panoramaæ•°æ®ï¼Œè·³è¿‡")
                continue
            
            p1_split = panoramas['panorama1']
            p2_split = panoramas['panorama2']
            
            # ç»„ç»‡æ’å€¼å›¾åƒæ•°æ®å’Œå‚æ•°
            p1_interp_data = []
            p2_interp_data = []
            p1_params_sequence = []
            p2_params_sequence = []
            
            for interp_group in interpolated_results:
                panorama = interp_group.get('panorama')
                interp_images = interp_group.get('interpolated_images', [])
                
                if panorama == 'panorama1' and interp_group.get('interval') == interval:
                    # æŒ‰ç…§ä»å·¦åˆ°å³çš„é¡ºåºç»„ç»‡ï¼šA1 (left) -> interp_01 -> ... -> interp_09 -> A2 (right)
                    images = [p1_split.get('left_image')]  # èµ·å§‹å·¦å›¾
                    params = [p1_split.get('main_params')]  # èµ·å§‹å·¦å›¾å‚æ•°
                    
                    for interp_img in sorted(interp_images, key=lambda x: x.get('weight_idx', 0)):
                        images.append(interp_img.get('super_resolved', interp_img.get('path')))
                        params.append(interp_img.get('params'))  # æ·»åŠ æ’å€¼å‚æ•°
                    
                    images.append(p1_split.get('right_image'))  # ç»“æŸå³å›¾
                    params.append(p1_split.get('rand_params'))  # ç»“æŸå³å›¾å‚æ•°
                    
                    p1_interp_data = images
                    p1_params_sequence = params
                    
                elif panorama == 'panorama2' and interp_group.get('interval') == interval:
                    images = [p2_split.get('left_image')]
                    params = [p2_split.get('main_params')]
                    
                    for interp_img in sorted(interp_images, key=lambda x: x.get('weight_idx', 0)):
                        images.append(interp_img.get('super_resolved', interp_img.get('path')))
                        params.append(interp_img.get('params'))
                    
                    images.append(p2_split.get('right_image'))
                    params.append(p2_split.get('rand_params'))
                    
                    p2_interp_data = images
                    p2_params_sequence = params
            
            # åˆ›å»ºæœ€ç»ˆæ•°æ®æ¡ç›®
            final_entry = {
                'group_id': group_id,
                'yaw_interval': {
                    'interval_id': interval,
                    'yaw_min': p1_split.get('yaw_interval', (0, 0))[0],
                    'yaw_max': p1_split.get('yaw_interval', (0, 0))[1]
                },
                'panorama1': {
                    'original_path': panorama1_path,
                    'interpolated_sequence': p1_interp_data,  # 11å¼ å›¾ç‰‡åºåˆ—
                    'params_sequence': p1_params_sequence     # 11ç»„å‚æ•°åºåˆ—
                },
                'panorama2': {
                    'original_path': panorama2_path,
                    'interpolated_sequence': p2_interp_data,  # 11å¼ å›¾ç‰‡åºåˆ—
                    'params_sequence': p2_params_sequence,    # 11ç»„å‚æ•°åºåˆ—
                    'right_image_description': descriptions_by_interval.get(interval, '')  # æ·»åŠ å³å›¾æè¿°
                }
            }
            
            final_data.append(final_entry)
            logger.info(f"åˆ›å»ºinterval {interval} çš„æœ€ç»ˆæ•°æ®æ¡ç›®ï¼ŒåŒ…å« {len(p1_interp_data)} + {len(p2_interp_data)} å¼ å›¾åƒ")
        
        logger.info(f"æœ€ç»ˆæ•°æ®åˆ›å»ºå®Œæˆï¼Œå…± {len(final_data)} ä¸ªæ¡ç›®")
        return final_data
    
    # ==================== ä¸»æµç¨‹ ====================
    
    def process_image_group(self, panorama_path1: str, panorama_path2: str, group_id: int) -> Dict:
        """å¤„ç†å›¾ç‰‡ç»„ï¼ˆä¸¤å¼ å…¨æ™¯å›¾ï¼‰
        
        æµç¨‹:
            1. é¢„å¤„ç† â†’ 2. è¶…åˆ† â†’ 3. è´¨é‡è¯„ä¼° â†’ 4. è´¨é‡è¿‡æ»¤
            â†’ 4.5. æè¿°ç”Ÿæˆ â†’ 5. åˆ‡åˆ†+æ’å€¼+æ’å€¼è¶…åˆ† â†’ 6. åˆ›å»ºæœ€ç»ˆæ•°æ®
        """
        logger.info(f"å¼€å§‹å¤„ç†å›¾ç‰‡ç»„ #{group_id}: {os.path.basename(panorama_path1)} + {os.path.basename(panorama_path2)}")
        start_time = time.time()
        
        try:
            # 1. é¢„å¤„ç†ä¸¤å¼ å…¨æ™¯å›¾
            path1 = os.path.abspath(panorama_path1) if not os.path.isabs(panorama_path1) else panorama_path1
            path2 = os.path.abspath(panorama_path2) if not os.path.isabs(panorama_path2) else panorama_path2
            
            resp1 = self._call_api(
                self.API_PORTS['preprocess'], 'preprocess_for_group',
                {'image_path': path1, 'group_id': group_id, 'is_first': True}, "é¢„å¤„ç†ç¬¬ä¸€å¼ "
            )
            resp2 = self._call_api(
                self.API_PORTS['preprocess'], 'preprocess_for_group',
                {'image_path': path2, 'group_id': group_id, 'is_first': False}, "é¢„å¤„ç†ç¬¬äºŒå¼ "
            )
            all_preprocess_results = resp1.get('results', []) + resp2.get('results', [])
            
            # 2. è¶…åˆ†è¾¨ç‡å¤„ç† - å±•å¼€åµŒå¥—ç»“æ„å¹¶æ‰¹é‡è¶…åˆ†
            flat_pairs = []
            for r in all_preprocess_results:
                if isinstance(r, list):
                    flat_pairs.extend(d for d in r if 'pair_image' in d)
                elif isinstance(r, dict) and 'pair_image' in r:
                    flat_pairs.append(r)
            
            valid_pairs = [d for d in flat_pairs if os.path.exists(d['pair_image'])]
            batch_sr = self._batch_super_resolve([d['pair_image'] for d in valid_pairs])
            
            sr_results = []
            for pair_data, sr_result in zip(valid_pairs, batch_sr):
                if sr_result.get('success'):
                    entry = pair_data.copy()
                    entry['super_resolved'] = sr_result['output_path']
                    entry['align_method'] = 'adain'
                    sr_results.append(entry)
            logger.info(f"è¶…åˆ†è¾¨ç‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸ {len(sr_results)}/{len(valid_pairs)}")
            
            # 3. è´¨é‡è¯„ä¼°
            quality_results = self.evaluate_quality(sr_results)
            
            # 4. è´¨é‡è¿‡æ»¤ï¼ˆæŒ‰ç»„å–æœ€ä½åˆ†ï¼‰
            filtered_results = self.filter_high_quality_results_by_group(quality_results, threshold=0.7)
            if not filtered_results:
                logger.warning(f"å›¾ç‰‡ç»„ #{group_id} æ²¡æœ‰é«˜è´¨é‡å›¾åƒ")
                return {
                    "group_id": group_id, "panorama1": panorama_path1, "panorama2": panorama_path2,
                    "error": "æ²¡æœ‰é«˜è´¨é‡å›¾åƒ", "processing_time": time.time() - start_time, "success": False
                }
            
            # 4.5. ä¸º panorama2 çš„å³å›¾ç”Ÿæˆæè¿°ï¼ˆéå…³é”®æ­¥éª¤ï¼‰
            desc_result = self.generate_panorama2_descriptions(filtered_results, panorama_path2, group_id)
            
            # 5. åˆ‡åˆ†ã€æ’å€¼ç”Ÿæˆã€æ’å€¼è¶…åˆ†ï¼ˆä¸€æ­¥å®Œæˆï¼‰
            split_results, interpolated_results = self.interpolate_and_super_resolve(
                filtered_results, group_id, panorama_path1, panorama_path2
            )
            
            # 6. åˆ›å»ºæœ€ç»ˆæ•°æ®ï¼ˆæŒ‰yawåŒºé—´ç»„ç»‡ï¼‰
            final_data = self.create_final_data_with_interpolation(
                split_results, interpolated_results,
                group_id, panorama_path1, panorama_path2, desc_result
            )
            
            processing_time = time.time() - start_time
            
            result = {
                "group_id": group_id,
                "panorama1": panorama_path1,
                "panorama2": panorama_path2,
                "final_data": final_data,
                "processing_time": processing_time,
                "success": True
            }
            
            logger.info(f"å›¾ç‰‡ç»„ #{group_id} å¤„ç†å®Œæˆ (è€—æ—¶: {processing_time:.2f}ç§’)")
            return result
            
        except Exception as e:
            logger.error(f"å¤„ç†å›¾ç‰‡ç»„ #{group_id} å¤±è´¥: {e}")
            return {
                "group_id": group_id,
                "panorama1": panorama_path1,
                "panorama2": panorama_path2,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "success": False
            }
    
    # ==================== å¤–éƒ¨è°ƒç”¨æ–¹æ³• ====================
    
    def save_single_group_result(self, result: Dict):
        """ä¿å­˜å•ä¸ªå›¾ç‰‡ç»„çš„å¤„ç†ç»“æœï¼ˆå®æ—¶ä¿å­˜ï¼‰"""
        try:
            # æ„å»ºå®Œæ•´çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_file_path = os.path.join(self.output_root_dir, self.output_file)
            
            # è¯»å–ç°æœ‰çš„results
            existing_results = []
            if os.path.exists(output_file_path):
                with open(output_file_path, 'r', encoding='utf-8') as f:
                    existing_results = json.load(f)
            
            # æ·»åŠ æœ¬æ¬¡çš„ç»“æœï¼ˆå¦‚æœæ˜¯æˆåŠŸçš„è¯ï¼‰
            if result.get('success', False) and 'final_data' in result:
                new_entries = result.get('final_data', [])
                existing_results.extend(new_entries)
                
                # ä¿å­˜æ›´æ–°çš„results.json
                with open(output_file_path, 'w', encoding='utf-8') as f:
                    json.dump(existing_results, f, ensure_ascii=False, indent=2)
                
                logger.info(f"å®æ—¶æ›´æ–° {self.output_file}ï¼Œå½“å‰å…±æœ‰ {len(existing_results)} ä¸ªæ•°æ®æ¡ç›®")
            
            # ç”Ÿæˆæˆ–æ›´æ–° group_info.jsonï¼ˆæ— è®ºæˆåŠŸå¤±è´¥éƒ½ç”Ÿæˆï¼‰
            group_id = result.get('group_id')
            panorama1 = result.get('panorama1', '')
            panorama2 = result.get('panorama2', '')
            processing_time = result.get('processing_time', 0)
            success = result.get('success', False)
            
            # ç¡®å®šgroupç›®å½•ä½ç½®
            group_dir_name = f"group_{group_id:04d}"
            if 'preprocess' in self.output_root_dir:
                parent_dir = os.path.dirname(self.output_root_dir)
                group_dir = os.path.join(parent_dir, group_dir_name)
            else:
                group_dir = os.path.join(self.output_root_dir, group_dir_name)
            
            # æ„å»ºgroup_info
            if success and 'final_data' in result:
                final_data = result.get('final_data', [])
                yaw_intervals = []
                for entry in final_data:
                    interval_info = entry.get('yaw_interval', {})
                    yaw_intervals.append({
                        'interval_id': interval_info.get('interval_id'),
                        'yaw_min': interval_info.get('yaw_min'),
                        'yaw_max': interval_info.get('yaw_max')
                    })
                
                group_info = {
                    'group_id': group_id,
                    'panorama1': os.path.basename(panorama1),
                    'panorama2': os.path.basename(panorama2),
                    'panorama1_path': panorama1,
                    'panorama2_path': panorama2,
                    'num_quadruples': len(final_data),
                    'yaw_intervals': yaw_intervals,
                    'processing_time': processing_time,
                    'success': True
                }
            else:
                # å¤±è´¥æˆ–æ²¡æœ‰é«˜è´¨é‡æ•°æ®çš„æƒ…å†µ
                error_msg = result.get('error', 'æ— æ•°æ®æˆ–å¤„ç†å¤±è´¥')
                group_info = {
                    'group_id': group_id,
                    'panorama1': os.path.basename(panorama1) if panorama1 else '',
                    'panorama2': os.path.basename(panorama2) if panorama2 else '',
                    'panorama1_path': panorama1 if panorama1 else '',
                    'panorama2_path': panorama2 if panorama2 else '',
                    'num_quadruples': 0,
                    'yaw_intervals': [],
                    'processing_time': processing_time,
                    'success': False,
                    'error': error_msg
                }
            
            # ä¿å­˜ group_info.json
            group_info_file = os.path.join(group_dir, 'group_info.json')
            with open(group_info_file, 'w', encoding='utf-8') as f:
                json.dump(group_info, f, ensure_ascii=False, indent=2)
            logger.info(f"ç»„ä¿¡æ¯å·²å®æ—¶ä¿å­˜: {group_info_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å•ä¸ªç»„ç»“æœå¤±è´¥: {e}")
    
    def count_current_intervals(self) -> int:
        """ç»Ÿè®¡å½“å‰ results.json ä¸­çš„ yaw_interval æ•°é‡"""
        output_file_path = os.path.join(self.output_root_dir, self.output_file)
        
        if not os.path.exists(output_file_path):
            return 0
        
        try:
            with open(output_file_path, 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            # results.json æ˜¯æ‰å¹³åŒ–çš„ yaw_interval åˆ—è¡¨
            # æ¯ä¸ªæ¡ç›®å°±æ˜¯ä¸€ä¸ª yaw_intervalï¼Œç›´æ¥è¿”å›åˆ—è¡¨é•¿åº¦
            if isinstance(results, list):
                return len(results)
            else:
                return 0
        except Exception as e:
            logger.warning(f"ç»Ÿè®¡ yaw_interval æ•°é‡æ—¶å‡ºé”™: {e}")
            return 0
